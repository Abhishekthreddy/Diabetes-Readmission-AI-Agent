# ğŸ¥ Diabetes Readmission AI Agent

A hybrid AI system combining **structured machine learning** (LightGBM) and **natural language processing** (NLP) to predict diabetes patient readmission risk and infer likely diagnoses from chief complaints.

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

---

## ğŸ¯ Features

- **ğŸ“Š Readmission Risk Prediction**: LightGBM model predicts 30-day readmission probability
- **ğŸ©º NLP Diagnosis Inference**: TF-IDF + Naive Bayes predicts likely diagnoses from chief complaints
- **ğŸ“ˆ SHAP Explanations**: Interpretable AI with top risk factor contributions
- **ğŸš€ REST API**: FastAPI endpoints deployed on AWS Lambda
- **ğŸ¨ Interactive UI**: Streamlit web interface for real-time predictions
- **ğŸ”„ Data Pipeline**: DBT models for feature engineering
- **â˜ï¸ Cloud-Ready**: Containerized deployment via AWS SAM

---

## ğŸ“Š Model Performance

| Model | Algorithm | Accuracy/Metric | Features |
|-------|-----------|-----------------|----------|
| Readmission Risk | LightGBM | ROC AUC (MLflow) | Age, Gender, Race |
| NLP Diagnosis | TF-IDF + Naive Bayes | 73.7% | 1000 TF-IDF features |
| SHAP Explainer | TreeExplainer | Top 5 factors | Same as risk model |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Streamlit UI                            â”‚
â”‚              (Patient Data + Chief Complaint)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  API Gateway + Lambda                        â”‚
â”‚                 POST /predict_combined                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                             â”‚
        â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Structured ML   â”‚         â”‚   NLP Diagnosis      â”‚
â”‚   (LightGBM)     â”‚         â”‚  (TF-IDF + NB)       â”‚
â”‚                  â”‚         â”‚                      â”‚
â”‚ â€¢ Age            â”‚         â”‚ â€¢ Chief Complaint    â”‚
â”‚ â€¢ Gender         â”‚         â”‚   (free text)        â”‚
â”‚ â€¢ Race           â”‚         â”‚                      â”‚
â”‚                  â”‚         â”‚ Output:              â”‚
â”‚ Output:          â”‚         â”‚ â€¢ Top 3 diagnoses    â”‚
â”‚ â€¢ Risk score     â”‚         â”‚ â€¢ Confidence scores  â”‚
â”‚ â€¢ SHAP values    â”‚         â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.12+
- Docker (for AWS deployment)
- AWS CLI configured (for deployment)
- Virtual environment

### Installation

```bash
# Clone the repository
git clone https://github.com/Abhishekthreddy/Diabetes-Readmission-AI-Agent.git
cd Diabetes-Readmission-AI-Agent

# Create and activate virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r readmission_api/requirements.txt
pip install -r requirments.txt  # UI dependencies
```

### Data Setup

```bash
# Place your Synthea CSV files in data/raw/Synthea/
# Then convert to Parquet format
python data_ingestion/convert_synthea_parquet.py

# Run DBT pipeline to create feature tables
cd dbt_pipeline/diabetes_agent
dbt run
cd ../..
```

### Train Models

```bash
cd readmission_api

# Train structured risk model
python ml/train_model.py

# Train SHAP explainer
python ml/explain_model.py

# Train NLP diagnosis model
python ml/train_nlp_diagnosis.py

cd ..
```

### Run Locally

**API Server:**
```bash
cd readmission_api
uvicorn api.main:app --reload --port 8000
```

**Streamlit UI:**
```bash
cd ui_streamlit
streamlit run app.py
```

**Test Combined Workflow:**
```bash
python test_combined_workflow.py
```

---

## ğŸ“¡ API Endpoints

### Combined Endpoint (Recommended)

**POST** `/predict_combined`

```json
{
  "age": 65,
  "gender": "male",
  "race": "white",
  "chief_complaint": "chest pain and shortness of breath"
}
```

**Response:**
```json
{
  "readmission_risk": 0.3988,
  "risk_factors": {
    "age": -0.320,
    "RACE_white": 0.075,
    "GENDER_M": 0.042
  },
  "predicted_diagnoses": [
    {
      "diagnosis": "Chronic congestive heart failure (disorder)",
      "probability": 0.8523
    }
  ]
}
```

### Legacy Endpoints

- **POST** `/predict` - Structured risk only
- **POST** `/explain` - SHAP explanations only
- **GET** `/` - API health check
- **GET** `/ping` - Ping endpoint

---

## â˜ï¸ AWS Deployment

### Build and Deploy

```bash
# Build Docker image
sam build --use-container --template template.yaml

# Deploy to AWS (first time)
sam deploy --guided

# Deploy (subsequent times)
sam deploy
```

### Configuration

Update `ui_streamlit/config.py` with your API Gateway URL:
```python
API_BASE_URL = "https://YOUR-API-ID.execute-api.us-east-1.amazonaws.com/Prod"
```

---

## ğŸ“ Project Structure

```
project-diabetes-ai-agent/
â”œâ”€â”€ data/                          # Data storage
â”‚   â”œâ”€â”€ raw/                       # Raw Synthea CSV files
â”‚   â””â”€â”€ processed/                 # Processed Parquet files
â”œâ”€â”€ data_ingestion/                # Data conversion scripts
â”œâ”€â”€ dbt_pipeline/                  # DBT data transformations
â”‚   â””â”€â”€ diabetes_agent/
â”‚       â””â”€â”€ models/
â”‚           â”œâ”€â”€ staging/           # Staging models
â”‚           â””â”€â”€ marts/             # Feature tables
â”œâ”€â”€ readmission_api/               # Main API application
â”‚   â”œâ”€â”€ api/                       # FastAPI endpoints
â”‚   â”‚   â”œâ”€â”€ main.py               # API app + routes
â”‚   â”‚   â”œâ”€â”€ predictor.py          # Risk prediction
â”‚   â”‚   â”œâ”€â”€ explainer.py          # SHAP explanations
â”‚   â”‚   â”œâ”€â”€ nlp_predictor.py      # NLP diagnosis
â”‚   â”‚   â””â”€â”€ schemas.py            # Pydantic models
â”‚   â”œâ”€â”€ ml/                        # ML training scripts
â”‚   â”‚   â”œâ”€â”€ train_model.py        # Train LightGBM
â”‚   â”‚   â”œâ”€â”€ train_nlp_diagnosis.py # Train NLP
â”‚   â”‚   â”œâ”€â”€ explain_model.py      # Train SHAP
â”‚   â”‚   â””â”€â”€ models/               # Trained models (.pkl)
â”‚   â”œâ”€â”€ Dockerfile                # Lambda container
â”‚   â””â”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ ui_streamlit/                  # Streamlit UI
â”‚   â”œâ”€â”€ app.py                    # Main UI
â”‚   â”œâ”€â”€ utils.py                  # API client
â”‚   â””â”€â”€ config.py                 # API URL config
â”œâ”€â”€ template.yaml                  # AWS SAM template
â”œâ”€â”€ test_combined_workflow.py      # Integration tests
â””â”€â”€ README.md                      # This file
```

---

## ğŸ”§ Development

### Running Tests

```bash
# Test combined workflow
python test_combined_workflow.py

# Test API endpoints
curl -X POST "http://localhost:8000/predict_combined" \
  -H "Content-Type: application/json" \
  -d '{"age": 65, "gender": "male", "race": "white", "chief_complaint": "chest pain"}'
```

### Code Structure

- **Path Resolution**: All paths use `Path(__file__)` for portability
- **Lazy Loading**: Models load on-demand for Lambda optimization
- **Type Safety**: Pydantic schemas for request/response validation
- **Logging**: Comprehensive logging via Python logging module

---

## ğŸ“š Documentation

- **[PROJECT_OUTLINE.md](PROJECT_OUTLINE.md)** - Comprehensive project overview
- **[WORKFLOW_IMPLEMENTATION.md](WORKFLOW_IMPLEMENTATION.md)** - Technical implementation details
- **[PATH_REFERENCE.md](PATH_REFERENCE.md)** - Path resolution guide

---

## ğŸ› ï¸ Tech Stack

### Backend
- **Python 3.12** - Programming language
- **FastAPI** - REST API framework
- **LightGBM** - Gradient boosting for risk prediction
- **scikit-learn** - NLP pipeline (TF-IDF + Naive Bayes)
- **SHAP** - Model explainability
- **pandas** - Data manipulation

### Data Pipeline
- **DBT** - Data transformation
- **DuckDB** - Analytics database
- **Parquet** - Columnar storage format

### ML Ops
- **MLflow** - Experiment tracking
- **joblib** - Model serialization

### Deployment
- **AWS Lambda** - Serverless compute
- **API Gateway** - HTTP API
- **Docker** - Containerization
- **AWS SAM** - Infrastructure as code

### Frontend
- **Streamlit** - Interactive web UI
- **requests** - HTTP client

---

## ğŸ“Š Data Sources

This project uses **Synthea** synthetic healthcare data:
- Patient demographics
- Encounter records with reason codes/descriptions
- Conditions and diagnoses

**Note**: Data files are not included in the repository due to size. Generate your own using [Synthea](https://github.com/synthetichealth/synthea).

---

## ğŸ” Environment Variables

Create a `.env` file for local development:

```env
# API Configuration
API_BASE_URL=http://localhost:8000

# AWS Configuration (for deployment)
AWS_REGION=us-east-1
AWS_ACCOUNT_ID=your-account-id

# MLflow (optional)
MLFLOW_TRACKING_URI=file:readmission_api/ml/mlflow_logs
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Synthea** - Synthetic healthcare data generation
- **FastAPI** - Modern web framework
- **LightGBM** - High-performance gradient boosting
- **SHAP** - Model interpretability

---

## ğŸ“§ Contact

For questions or support, please open an issue on GitHub.

---

## ğŸ—ºï¸ Roadmap

### Current Version (v1.0)
- âœ… Structured risk prediction
- âœ… NLP diagnosis inference
- âœ… Combined API endpoint
- âœ… Streamlit UI
- âœ… AWS Lambda deployment

### Future Enhancements
- [ ] Add more structured features (medications, lab results)
- [ ] Fine-tune BERT/BioBERT for medical NLP
- [ ] Implement RAG with medical knowledge base
- [ ] Multi-label classification for comorbidities
- [ ] Model versioning and A/B testing
- [ ] Real-time monitoring and alerting
- [ ] Automated retraining pipeline

---

**Built with â¤ï¸ for better healthcare outcomes**

